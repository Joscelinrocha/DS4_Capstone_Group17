{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joscelin is following these steps: https://github.com/Sandeep-Panchal/Topic-Modeling-with-LDA/blob/master/Topic-Modeling-IPYNB/Topic%20Modeling%20with%20LDA.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>ls_tokens</th>\n",
       "      <th>new_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>[nerdy, guy, love, art, music, wrestle, comics...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>[worry, sunshine, cause, mess, woman, moon, ci...</td>\n",
       "      <td>worry sunshine cause mess woman moon civil rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>[sport, music, fan, graduate, regis, universit...</td>\n",
       "      <td>sport music fan graduate regis university live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "      <td>[endorse, government, entity, project, guarant...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "      <td>[writer, cult, film, fanatic, love, politics]</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>2.961228e+08</td>\n",
       "      <td>Christian. Husband. Father. Ph.D. Candidate @B...</td>\n",
       "      <td>christian husband father candidate mosquito re...</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>[christian, husband, father, candidate, mosqui...</td>\n",
       "      <td>christian husband father candidate mosquito re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>MarTech, MBA, Foodie, Bilingual, Soccer, Boxin...</td>\n",
       "      <td>martech mba foodie bilingual soccer box gamer ...</td>\n",
       "      <td>CA</td>\n",
       "      <td>West</td>\n",
       "      <td>[martech, mba, foodie, bilingual, soccer, box,...</td>\n",
       "      <td>martech mba foodie bilingual soccer box gamer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1.153059e+09</td>\n",
       "      <td>streams occasionally, will choose race cars ov...</td>\n",
       "      <td>stream occasionally choose race cars important...</td>\n",
       "      <td>KY</td>\n",
       "      <td>South</td>\n",
       "      <td>[stream, occasionally, choose, race, cars, imp...</td>\n",
       "      <td>stream occasionally choose race cars important...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2.432869e+08</td>\n",
       "      <td>Enjoy the practical wisdom of daily life. Prom...</td>\n",
       "      <td>enjoy practical wisdom daily life promote trut...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>[enjoy, practical, wisdom, daily, life, promot...</td>\n",
       "      <td>enjoy practical wisdom daily life promote trut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>2.159799e+09</td>\n",
       "      <td>glass half full</td>\n",
       "      <td>glass half</td>\n",
       "      <td>MO</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>[glass]</td>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                                           user_bio  \\\n",
       "0     1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1     1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2     1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3     1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4     2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "...            ...                                                ...   \n",
       "1723  2.961228e+08  Christian. Husband. Father. Ph.D. Candidate @B...   \n",
       "1724  8.800000e+17  MarTech, MBA, Foodie, Bilingual, Soccer, Boxin...   \n",
       "1725  1.153059e+09  streams occasionally, will choose race cars ov...   \n",
       "1726  2.432869e+08  Enjoy the practical wisdom of daily life. Prom...   \n",
       "1727  2.159799e+09                                    glass half full   \n",
       "\n",
       "                                                 tokens state     region  \\\n",
       "0          nerdy guy love art music wrestle comics poly    OH    Midwest   \n",
       "1     worry lil sunshine cause mess woman moon civil...    PA  Northeast   \n",
       "2     huge sport music fan graduate regis university...    CO       West   \n",
       "3     endorse government entity project guarantee wa...    WA       West   \n",
       "4                writer cult film fanatic love politics    UT       West   \n",
       "...                                                 ...   ...        ...   \n",
       "1723  christian husband father candidate mosquito re...    OH    Midwest   \n",
       "1724  martech mba foodie bilingual soccer box gamer ...    CA       West   \n",
       "1725  stream occasionally choose race cars important...    KY      South   \n",
       "1726  enjoy practical wisdom daily life promote trut...    AZ  Southwest   \n",
       "1727                                         glass half    MO    Midwest   \n",
       "\n",
       "                                              ls_tokens  \\\n",
       "0     [nerdy, guy, love, art, music, wrestle, comics...   \n",
       "1     [worry, sunshine, cause, mess, woman, moon, ci...   \n",
       "2     [sport, music, fan, graduate, regis, universit...   \n",
       "3     [endorse, government, entity, project, guarant...   \n",
       "4         [writer, cult, film, fanatic, love, politics]   \n",
       "...                                                 ...   \n",
       "1723  [christian, husband, father, candidate, mosqui...   \n",
       "1724  [martech, mba, foodie, bilingual, soccer, box,...   \n",
       "1725  [stream, occasionally, choose, race, cars, imp...   \n",
       "1726  [enjoy, practical, wisdom, daily, life, promot...   \n",
       "1727                                            [glass]   \n",
       "\n",
       "                                             new_tokens  \n",
       "0          nerdy guy love art music wrestle comics poly  \n",
       "1     worry sunshine cause mess woman moon civil rig...  \n",
       "2     sport music fan graduate regis university live...  \n",
       "3     endorse government entity project guarantee wa...  \n",
       "4                writer cult film fanatic love politics  \n",
       "...                                                 ...  \n",
       "1723  christian husband father candidate mosquito re...  \n",
       "1724  martech mba foodie bilingual soccer box gamer ...  \n",
       "1725  stream occasionally choose race cars important...  \n",
       "1726  enjoy practical wisdom daily life promote trut...  \n",
       "1727                                              glass  \n",
       "\n",
       "[1644 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/twitter_data_clean_final.csv')\n",
    "df = df.loc[:,[\"user_id\",\"user_bio\",\"tokens\",\"state\",\"region\"]]\n",
    "df.dropna(inplace=True)\n",
    "df\n",
    "# deep copy to avoid override of the original dataframe\n",
    "import copy\n",
    "\n",
    "df_new = copy.deepcopy(df)\n",
    "\n",
    "to_remove = ['act', 'car', 'card', 'acct','acab','ada','admin','aew','age', 'ain', 'aka','alt','alum', 'angeleno', 'answer','antonio','app',\n",
    "            'area','ask','atl', 'ben', 'brady','brandon', 'chair','circle','clue','collab','com', 'come', 'day', 'dedicate',\n",
    "            'dev', 'dms', 'dont', 'dot', 'drive', 'driver', 'eat', 'email', 'eth', 'feed', 'form', 'fsu', 'gas', 'giants',\n",
    "            'google', 'group', 'hair', 'half','harris', 'head','hear','hip', 'hire','hit','hiv','holder','host', 'hold',\n",
    "            'huge', 'ill', 'info', 'inquire','inquires', 'internet', 'investor', 'investors', 'jeff', 'jack', 'job', 'joe',\n",
    "            'john', 'join', 'know', 'las', 'lake', ' let', 'lil', 'line', 'link','listen', 'little', 'llc', 'los', 'main', \n",
    "            'meet', 'member', 'miles', 'mma', 'multi','near', 'need', 'nice', 'nominate', 'non', 'nut', 'okay', 'open', \n",
    "            'order', 'padres', 'page', 'park', 'pin', 'plug', 'print','provide', 'providence', 'ram', 'sag', 'say', 'sell', 'set', \n",
    "            'stl','sth','sub', 'syndication', 'tell', 'tony', 'true', 'try', 'tryna', 'type', 'typos', 'usa', 'use', 'valley', \n",
    "            'verse', 'view', 'way', 'year', 'years', 'yrs']\n",
    "\n",
    "\n",
    "            \n",
    "def stringToList(string):\n",
    "    listRes = list(string.split(\" \"))\n",
    "    return listRes\n",
    "\n",
    "ls_tokens = []  \n",
    "\n",
    "for cell in df_new.tokens: \n",
    "    cell = stringToList(cell)\n",
    "    ls_tokens.append(cell)\n",
    "    \n",
    "\n",
    "\n",
    "for cell in ls_tokens: \n",
    "    for word in list(cell):\n",
    "        if word in to_remove:\n",
    "            cell.remove(word)\n",
    "            \n",
    "df_new['ls_tokens'] = ls_tokens\n",
    "\n",
    "df_new['new_tokens'] = [' '.join(map(str, l)) for l in df_new['ls_tokens']]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the sparse matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1644x825 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6348 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing TFIDF vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# creating an instance\n",
    "cv = CountVectorizer(max_df = 0.90, min_df = 3, stop_words = 'english')\n",
    "\n",
    "# fit and transform the text data\n",
    "cv_fit = cv.fit_transform(df_new.new_tokens)\n",
    "\n",
    "print('\\nShape of the sparse matrix\\n')\n",
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Latent Dirichlet Allocation library\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# creating an instance for LDA\n",
    "lda = LatentDirichletAllocation(n_components = 55, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer with the LDA\n",
      "CPU times: user 3.7 s, sys: 26.1 ms, total: 3.72 s\n",
      "Wall time: 3.92 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=55, random_state=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Fitting the vectorizer with the LDA')\n",
    "\n",
    "lda.fit(cv_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topic: 55\n",
      "Number of column of the lda fit: 825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, min_df=3, stop_words='english')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of topic:', len(lda.components_))\n",
    "print('Number of column of the lda fit:',len(lda.components_[0]))\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature names: 825\n"
     ]
    }
   ],
   "source": [
    "feature = cv.get_feature_names()\n",
    "\n",
    "print('Length of feature names:', len(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, topic in enumerate(lda.components_):\n",
    "    print('top 50 words in topic {}'.format(ind))\n",
    "    print('-'*25)\n",
    "    top_50 = topic.argsort()[-50:]\n",
    "    print([feature[i] for i in top_50], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the df_final: (1644, 55)\n"
     ]
    }
   ],
   "source": [
    "# transform \n",
    "df_final = lda.transform(cv_fit)\n",
    "\n",
    "print('Shape of the df_final:', df_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking the probabilitiy distribution of one text data belonging to the topic.\n",
      "\n",
      "Few words from 1st row: nerdy guy love art music wrestle comics poly \n",
      "\n",
      "Probability distribution: [0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.19548862 0.0025974  0.14927643 0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.1535443  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.36922311 0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974  0.0025974  0.0025974  0.0025974  0.0025974  0.0025974\n",
      " 0.0025974 ]\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking the probabilitiy distribution of one text data belonging to the topic.\\n')\n",
    "print('Few words from 1st row:', df_new.new_tokens[0][:88],'\\n')\n",
    "print('Probability distribution:', df_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bio belonging to the topic 43 with the probability of 0.37\n"
     ]
    }
   ],
   "source": [
    "prob = df_final[0][df_final[0].argmax()].round(2)\n",
    "\n",
    "print('Bio belonging to the topic', df_final[0].argmax(), 'with the probability of', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>ls_tokens</th>\n",
       "      <th>new_tokens</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>[nerdy, guy, love, art, music, wrestle, comics...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>[worry, sunshine, cause, mess, woman, moon, ci...</td>\n",
       "      <td>worry sunshine cause mess woman moon civil rig...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>[sport, music, fan, graduate, regis, universit...</td>\n",
       "      <td>sport music fan graduate regis university live...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "      <td>[endorse, government, entity, project, guarant...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "      <td>[writer, cult, film, fanatic, love, politics]</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                           user_bio  \\\n",
       "0  1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1  1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2  1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3  1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4  2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "\n",
       "                                              tokens state     region  \\\n",
       "0       nerdy guy love art music wrestle comics poly    OH    Midwest   \n",
       "1  worry lil sunshine cause mess woman moon civil...    PA  Northeast   \n",
       "2  huge sport music fan graduate regis university...    CO       West   \n",
       "3  endorse government entity project guarantee wa...    WA       West   \n",
       "4             writer cult film fanatic love politics    UT       West   \n",
       "\n",
       "                                           ls_tokens  \\\n",
       "0  [nerdy, guy, love, art, music, wrestle, comics...   \n",
       "1  [worry, sunshine, cause, mess, woman, moon, ci...   \n",
       "2  [sport, music, fan, graduate, regis, universit...   \n",
       "3  [endorse, government, entity, project, guarant...   \n",
       "4      [writer, cult, film, fanatic, love, politics]   \n",
       "\n",
       "                                          new_tokens  cluster  \n",
       "0       nerdy guy love art music wrestle comics poly       43  \n",
       "1  worry sunshine cause mess woman moon civil rig...       52  \n",
       "2  sport music fan graduate regis university live...       38  \n",
       "3  endorse government entity project guarantee wa...        9  \n",
       "4             writer cult film fanatic love politics       21  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['cluster'] = df_final.argmax(axis = 1)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>ls_tokens</th>\n",
       "      <th>new_tokens</th>\n",
       "      <th>cluster</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>[nerdy, guy, love, art, music, wrestle, comics...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>[worry, sunshine, cause, mess, woman, moon, ci...</td>\n",
       "      <td>worry sunshine cause mess woman moon civil rig...</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>[sport, music, fan, graduate, regis, universit...</td>\n",
       "      <td>sport music fan graduate regis university live...</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "      <td>[endorse, government, entity, project, guarant...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>Classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "      <td>[writer, cult, film, fanatic, love, politics]</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                           user_bio  \\\n",
       "0  1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1  1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2  1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3  1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4  2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "\n",
       "                                              tokens state     region  \\\n",
       "0       nerdy guy love art music wrestle comics poly    OH    Midwest   \n",
       "1  worry lil sunshine cause mess woman moon civil...    PA  Northeast   \n",
       "2  huge sport music fan graduate regis university...    CO       West   \n",
       "3  endorse government entity project guarantee wa...    WA       West   \n",
       "4             writer cult film fanatic love politics    UT       West   \n",
       "\n",
       "                                           ls_tokens  \\\n",
       "0  [nerdy, guy, love, art, music, wrestle, comics...   \n",
       "1  [worry, sunshine, cause, mess, woman, moon, ci...   \n",
       "2  [sport, music, fan, graduate, regis, universit...   \n",
       "3  [endorse, government, entity, project, guarant...   \n",
       "4      [writer, cult, film, fanatic, love, politics]   \n",
       "\n",
       "                                          new_tokens  cluster      genre  \n",
       "0       nerdy guy love art music wrestle comics poly       43        NaN  \n",
       "1  worry sunshine cause mess woman moon civil rig...       52        NaN  \n",
       "2  sport music fan graduate regis university live...       38        NaN  \n",
       "3  endorse government entity project guarantee wa...        9  Classical  \n",
       "4             writer cult film fanatic love politics       21        NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dictionary with key as topic numbers and value as topic names\n",
    "#Joscelin used random genres here to see if everything is working\n",
    "\n",
    "topic_label = {0:'Pop', 1:'Latin', 2:'R&B', 3:'Rock', 4:'HipHop', 5:'HipHop',6:'Christian/Gospel', 7:'EDM',8:'Children',9:'Classical', 10:'World'}\n",
    "\n",
    "# mapping the dictionary with the dataframe to get the labels.\n",
    "df_new['genre'] = df_new['cluster'].map(topic_label)\n",
    "\n",
    "# head of the dataframe\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
