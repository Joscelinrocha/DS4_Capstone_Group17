{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joscelin is following these steps: https://github.com/Sandeep-Panchal/Topic-Modeling-with-LDA/blob/master/Topic-Modeling-IPYNB/Topic%20Modeling%20with%20LDA.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>2.961228e+08</td>\n",
       "      <td>Christian. Husband. Father. Ph.D. Candidate @B...</td>\n",
       "      <td>christian husband father candidate mosquito re...</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>MarTech, MBA, Foodie, Bilingual, Soccer, Boxin...</td>\n",
       "      <td>martech mba foodie bilingual soccer box gamer ...</td>\n",
       "      <td>CA</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1.153059e+09</td>\n",
       "      <td>streams occasionally, will choose race cars ov...</td>\n",
       "      <td>stream occasionally choose race cars important...</td>\n",
       "      <td>KY</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2.432869e+08</td>\n",
       "      <td>Enjoy the practical wisdom of daily life. Prom...</td>\n",
       "      <td>enjoy practical wisdom daily life promote trut...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>2.159799e+09</td>\n",
       "      <td>glass half full</td>\n",
       "      <td>glass half</td>\n",
       "      <td>MO</td>\n",
       "      <td>Midwest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                                           user_bio  \\\n",
       "0     1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1     1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2     1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3     1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4     2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "...            ...                                                ...   \n",
       "1723  2.961228e+08  Christian. Husband. Father. Ph.D. Candidate @B...   \n",
       "1724  8.800000e+17  MarTech, MBA, Foodie, Bilingual, Soccer, Boxin...   \n",
       "1725  1.153059e+09  streams occasionally, will choose race cars ov...   \n",
       "1726  2.432869e+08  Enjoy the practical wisdom of daily life. Prom...   \n",
       "1727  2.159799e+09                                    glass half full   \n",
       "\n",
       "                                                 tokens state     region  \n",
       "0          nerdy guy love art music wrestle comics poly    OH    Midwest  \n",
       "1     worry lil sunshine cause mess woman moon civil...    PA  Northeast  \n",
       "2     huge sport music fan graduate regis university...    CO       West  \n",
       "3     endorse government entity project guarantee wa...    WA       West  \n",
       "4                writer cult film fanatic love politics    UT       West  \n",
       "...                                                 ...   ...        ...  \n",
       "1723  christian husband father candidate mosquito re...    OH    Midwest  \n",
       "1724  martech mba foodie bilingual soccer box gamer ...    CA       West  \n",
       "1725  stream occasionally choose race cars important...    KY      South  \n",
       "1726  enjoy practical wisdom daily life promote trut...    AZ  Southwest  \n",
       "1727                                         glass half    MO    Midwest  \n",
       "\n",
       "[1644 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/twitter_data_clean_final.csv')\n",
    "df = df.loc[:,[\"user_id\",\"user_bio\",\"tokens\",\"state\",\"region\"]]\n",
    "df.dropna(inplace=True)\n",
    "df\n",
    "# deep copy to avoid override of the original dataframe\n",
    "import copy\n",
    "\n",
    "df_new = copy.deepcopy(df)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the sparse matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1644x955 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing TFIDF vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# creating an instance\n",
    "cv = CountVectorizer(max_df = 0.90, min_df = 3, stop_words = 'english')\n",
    "\n",
    "# fit and transform the text data\n",
    "cv_fit = cv.fit_transform(df_new.tokens)\n",
    "\n",
    "print('\\nShape of the sparse matrix\\n')\n",
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Latent Dirichlet Allocation library\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# creating an instance for LDA\n",
    "lda = LatentDirichletAllocation(n_components = 10, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the vectorizer with the LDA\n",
      "CPU times: user 4.09 s, sys: 34.3 ms, total: 4.13 s\n",
      "Wall time: 4.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(random_state=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Fitting the vectorizer with the LDA')\n",
    "\n",
    "lda.fit(cv_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topic: 10\n",
      "Number of column of the lda fit: 955\n"
     ]
    }
   ],
   "source": [
    "print('Number of topic:', len(lda.components_))\n",
    "print('Number of column of the lda fit:',len(lda.components_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature names: 955\n"
     ]
    }
   ],
   "source": [
    "feature = cv.get_feature_names()\n",
    "\n",
    "print('Length of feature names:', len(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50 words in topic 0\n",
      "-------------------------\n",
      "['ucla', 'publish', 'woman', 'boy', 'fight', 'student', 'ceo', 'state', 'wrestle', 'play', 'chicago', 'family', 'instagram', 'jesus', 'right', 'women', 'media', 'designer', 'love', 'know', 'film', 'journalist', 'inquiries', 'podcaster', 'producer', 'good', 'years', 'fan', 'alum', 'city', 'texas', 'long', 'business', 'photography', 'win', 'college', 'blm', 'owner', 'university', 'book', 'coach', 'podcast', 'things', 'author', 'man', 'writer', 'time', 'sport', 'com', 'host'] \n",
      "\n",
      "\n",
      "top 50 words in topic 1\n",
      "-------------------------\n",
      "['look', 'peace', 'single', 'professional', 'future', 'aficionado', 'eth', 'biden', 'near', 'old', 'run', 'listen', 'bless', 'bring', 'forever', 'let', 'long', 'art', 'fan', 'pay', 'day', 'enjoy', 'save', 'florida', 'everyday', 'school', 'arts', 'twitch', 'writer', 'life', 'member', 'business', 'partner', 'hate', 'study', 'shit', 'people', 'designer', 'photographer', 'like', 'play', 'email', 'guy', 'com', 'world', 'sport', 'matter', 'black', 'love', 'live'] \n",
      "\n",
      "\n",
      "top 50 words in topic 2\n",
      "-------------------------\n",
      "['world', 'video', 'dream', 'lead', 'company', 'web', 'california', 'southern', 'industry', 'amateur', 'mother', 'rip', 'boy', 'beautiful', 'proud', 'fan', 'dedicate', 'actress', 'radio', 'advocate', 'senior', 'yrs', 'bartender', 'educator', 'job', 'work', 'bio', 'american', 'cat', 'book', 'help', 'time', 'look', 'kid', 'health', 'producer', 'design', 'engineer', 'insta', 'snap', 'live', 'try', 'raise', 'life', 'fun', 'old', 'artist', 'marry', 'mom', 'photographer'] \n",
      "\n",
      "\n",
      "top 50 words in topic 3\n",
      "-------------------------\n",
      "['medical', 'walk', 'conservative', 'past', 'leader', 'meteorologist', 'mask', 'professional', 'major', 'animals', 'drink', 'want', 'dad', 'son', 'guy', 'years', 'enjoy', 'travel', 'plant', 'earth', 'las', 'group', 'diego', 'blogger', 'market', 'talk', 'account', 'know', 'bear', 'club', 'life', 'proud', 'vet', 'california', 'better', 'democrat', 'san', 'future', 'home', 'family', 'music', 'owner', 'retire', 'football', 'work', 'vegas', 'come', 'die', 'love', 'state'] \n",
      "\n",
      "\n",
      "top 50 words in topic 4\n",
      "-------------------------\n",
      "['previously', 'software', 'use', 'art', 'place', 'opinions', 'base', 'app', 'media', 'world', 'engineer', 'host', 'people', 'mix', 'creator', 'photographer', 'great', 'game', 'science', 'tweet', 'person', 'creative', 'band', 'worker', 'specialist', 'coach', 'content', 'director', 'nurse', 'alum', 'podcast', 'friends', 'twitter', 'social', 'develop', 'syndication', 'unmonitored', 'contact', 'husband', 'national', 'manager', 'service', 'office', 'love', 'page', 'retire', 'music', 'weather', 'dad', 'new'] \n",
      "\n",
      "\n",
      "top 50 words in topic 5\n",
      "-------------------------\n",
      "['guy', 'ceo', 'real', 'coach', 'cinematographer', 'transplant', 'want', 'navy', 'park', 'opinions', 'tell', 'native', 'artist', 'driver', 'ambassador', 'feel', 'service', 'day', 'writer', 'producer', 'music', 'star', 'american', 'lot', 'currently', 'model', 'fan', 'wanna', 'way', 'nsfw', 'win', 'gamer', 'work', 'member', 'brand', 'bad', 'play', 'hard', 'create', 'founder', 'actor', 'good', 'angeles', 'los', 'content', 'tweet', 'cat', 'creator', 'like', 'best'] \n",
      "\n",
      "\n",
      "top 50 words in topic 6\n",
      "-------------------------\n",
      "['warriors', 'blood', 'trade', 'trader', 'journey', 'self', 'taste', 'open', 'anime', 'mind', 'speak', 'man', 'sport', 'game', 'shoot', 'owner', 'horror', 'buy', 'soul', 'history', 'update', 'leave', 'mom', 'designer', 'family', 'video', 'media', 'dog', 'york', 'artist', 'father', 'follow', 'real', 'light', 'like', 'life', 'bitch', 'love', 'link', 'welcome', 'enthusiast', 'crypto', 'stream', 'art', 'state', 'lover', 'new', 'instagram', 'god', 'music'] \n",
      "\n",
      "\n",
      "top 50 words in topic 7\n",
      "-------------------------\n",
      "['francisco', 'culture', 'bean', 'marry', 'army', 'sagittarius', 'progressive', 'change', 'report', 'connecticut', 'nft', 'star', 'sport', 'pro', 'streamer', 'like', 'official', 'collector', 'open', 'cover', 'estate', 'writer', 'book', 'snap', 'tweet', 'time', 'affiliate', 'school', 'learn', 'war', 'read', 'acct', 'professional', 'business', 'proud', 'veteran', 'opinions', 'twitch', 'husband', 'san', 'game', 'politics', 'real', 'view', 'founder', 'fan', 'ceo', 'nerd', 'father', 'account'] \n",
      "\n",
      "\n",
      "top 50 words in topic 8\n",
      "-------------------------\n",
      "['adventure', 'champion', 'dancer', 'pop', 'true', 'nigga', 'tattoo', 'culture', 'bear', 'time', 'health', 'travel', 'want', 'videos', 'god', 'bisexual', 'friend', 'grad', 'post', 'art', 'new', 'dog', 'instagram', 'entrepreneur', 'break', 'baseball', 'think', 'make', 'nerd', 'news', 'owner', 'model', 'nyc', 'good', 'photographer', 'account', 'ass', 'like', 'life', 'cashapp', 'music', 'tweet', 'artist', 'big', 'old', 'girl', 'snapchat', 'know', 'follow', 'love'] \n",
      "\n",
      "\n",
      "top 50 words in topic 9\n",
      "-------------------------\n",
      "['single', 'read', 'friend', 'multi', 'news', 'award', 'tell', 'rock', 'bear', 'twitter', 'bay', 'game', 'lose', 'house', 'oakland', 'like', 'catch', 'singer', 'engineer', 'favorite', 'movies', 'wrestle', 'follow', 'player', 'let', 'pro', 'songwriter', 'time', 'mom', 'joke', 'head', 'com', 'free', 'fanatic', 'record', 'mother', 'write', 'huge', 'artist', 'actor', 'lover', 'big', 'dog', 'baseball', 'producer', 'love', 'writer', 'music', 'life', 'fan'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, topic in enumerate(lda.components_):\n",
    "    print('top 50 words in topic {}'.format(ind))\n",
    "    print('-'*25)\n",
    "    top_50 = topic.argsort()[-50:]\n",
    "    print([feature[i] for i in top_50], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the df_final: (1644, 10)\n"
     ]
    }
   ],
   "source": [
    "# transform \n",
    "df_final = lda.transform(cv_fit)\n",
    "\n",
    "print('Shape of the df_final:', df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking the probabilitiy distribution of one text data belonging to the topic.\n",
      "\n",
      "Few words from 1st row: nerdy guy love art music wrestle comics poly \n",
      "\n",
      "Probability distribution: [0.01428794 0.01429119 0.01428628 0.01428837 0.01428778 0.01428781\n",
      " 0.87140375 0.01428577 0.01429159 0.01428953]\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking the probabilitiy distribution of one text data belonging to the topic.\\n')\n",
    "print('Few words from 1st row:', df_new.tokens[0][:88],'\\n')\n",
    "print('Probability distribution:', df_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bio belonging to the topic 6 with the probability of 0.87\n"
     ]
    }
   ],
   "source": [
    "prob = df_final[0][df_final[0].argmax()].round(2)\n",
    "\n",
    "print('Bio belonging to the topic', df_final[0].argmax(), 'with the probability of', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                           user_bio  \\\n",
       "0  1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1  1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2  1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3  1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4  2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "\n",
       "                                              tokens state     region  topic  \n",
       "0       nerdy guy love art music wrestle comics poly    OH    Midwest      6  \n",
       "1  worry lil sunshine cause mess woman moon civil...    PA  Northeast      0  \n",
       "2  huge sport music fan graduate regis university...    CO       West      9  \n",
       "3  endorse government entity project guarantee wa...    WA       West      2  \n",
       "4             writer cult film fanatic love politics    UT       West      9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['topic'] = df_final.argmax(axis = 1)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_bio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.180000e+18</td>\n",
       "      <td>I'm a nerdy guy who loves art, music, wrestlin...</td>\n",
       "      <td>nerdy guy love art music wrestle comics poly</td>\n",
       "      <td>OH</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>6</td>\n",
       "      <td>Christian/Gospel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.440000e+18</td>\n",
       "      <td>No worries Lil Ms Sunshine cause I don't mess ...</td>\n",
       "      <td>worry lil sunshine cause mess woman moon civil...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>0</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.219720e+08</td>\n",
       "      <td>I am a huge sports and music fan. I graduated ...</td>\n",
       "      <td>huge sport music fan graduate regis university...</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>9</td>\n",
       "      <td>Classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.390000e+18</td>\n",
       "      <td>This is not, nor endorsed by, any Government E...</td>\n",
       "      <td>endorse government entity project guarantee wa...</td>\n",
       "      <td>WA</td>\n",
       "      <td>West</td>\n",
       "      <td>2</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.349053e+07</td>\n",
       "      <td>I'm a writer and a cult film fanatic who loves...</td>\n",
       "      <td>writer cult film fanatic love politics</td>\n",
       "      <td>UT</td>\n",
       "      <td>West</td>\n",
       "      <td>9</td>\n",
       "      <td>Classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                           user_bio  \\\n",
       "0  1.180000e+18  I'm a nerdy guy who loves art, music, wrestlin...   \n",
       "1  1.440000e+18  No worries Lil Ms Sunshine cause I don't mess ...   \n",
       "2  1.219720e+08  I am a huge sports and music fan. I graduated ...   \n",
       "3  1.390000e+18  This is not, nor endorsed by, any Government E...   \n",
       "4  2.349053e+07  I'm a writer and a cult film fanatic who loves...   \n",
       "\n",
       "                                              tokens state     region  topic  \\\n",
       "0       nerdy guy love art music wrestle comics poly    OH    Midwest      6   \n",
       "1  worry lil sunshine cause mess woman moon civil...    PA  Northeast      0   \n",
       "2  huge sport music fan graduate regis university...    CO       West      9   \n",
       "3  endorse government entity project guarantee wa...    WA       West      2   \n",
       "4             writer cult film fanatic love politics    UT       West      9   \n",
       "\n",
       "         topic_name  \n",
       "0  Christian/Gospel  \n",
       "1               Pop  \n",
       "2         Classical  \n",
       "3               R&B  \n",
       "4         Classical  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dictionary with key as topic numbers and value as topic names\n",
    "#Joscelin used random genres here to see if everything is working\n",
    "\n",
    "topic_label = {0:'Pop', 1:'Latin', 2:'R&B', 3:'Rock', 4:'HipHop', 5:'HipHop',6:'Christian/Gospel', 7:'EDM',8:'Children',9:'Classical', 10:'World'}\n",
    "\n",
    "# mapping the dictionary with the dataframe to get the labels.\n",
    "df_new['topic_name'] = df_new['topic'].map(topic_label)\n",
    "\n",
    "# head of the dataframe\n",
    "df_new.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
